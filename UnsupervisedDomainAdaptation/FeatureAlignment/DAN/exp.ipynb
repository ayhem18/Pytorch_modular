{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "home = os.getcwd()\n",
    "current = home\n",
    "while 'data' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "DATA_FOLDER = os.path.join(current, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dir = os.path.join(DATA_FOLDER, 'amazon', 'amazon')\n",
    "amazon_train = os.path.join(DATA_FOLDER, 'amazon', 'amazon_splitted', 'train')\n",
    "amazon_val = os.path.join(DATA_FOLDER, 'amazon', 'amazon_splitted', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple, List, Union\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from mypt.distances.MMD import GaussianMMD\n",
    "from transferable_alexnet import TransferAlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(source_logits: torch.Tensor, \n",
    "                   source_labels: torch.Tensor,\n",
    "                   source_features: List[torch.Tensor], \n",
    "                   target_features: List[torch.Tensor], \n",
    "                   loss_coefficient: float,\n",
    "                   reduction: str = 'mean', \n",
    "                   sigma: float = 0.5) -> Tuple[torch.tensor, torch.Tensor, List[torch.Tensor]]:\n",
    "    \n",
    "    if len(source_features) != len(target_features):\n",
    "        raise ValueError(f\"Please make sure the number of features is the same acoss target and source domains\")\n",
    "\n",
    "    # first part is the cross entropy loss as usual\n",
    "    cls_loss = nn.CrossEntropyLoss(reduction=reduction).forward(source_logits, source_labels)\n",
    "    \n",
    "    # this is the main object used for backpropagation\n",
    "    domain_confusion_loss = None    \n",
    "\n",
    "    # a list to store and track the different similarities along with training\n",
    "    distribution_losses = []\n",
    "\n",
    "    for fs, ft in zip(source_features, target_features):\n",
    "        loss_obj = GaussianMMD(sigma=sigma).forward(x=fs, y=ft)\n",
    "\n",
    "        distribution_losses.append(loss_obj.detach().cpu())\n",
    "\n",
    "        if domain_confusion_loss is None:\n",
    "            domain_confusion_loss = deepcopy(loss_obj)\n",
    "        else: \n",
    "            domain_confusion_loss += loss_obj\n",
    "\n",
    "    return cls_loss + loss_coefficient * domain_confusion_loss, cls_loss, distribution_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tr\n",
    "import mypt.utilities.directories_and_files as dirf\n",
    "from mypt.data.dataloaders.standard_dataloaders import initialize_train_dataloader\n",
    "\n",
    "def get_dataloader(root: Union[str, Path],\n",
    "                   image_transform:tr, \n",
    "                   batch_size: int,\n",
    "                   seed: int, \n",
    "                   num_workers: int = 2) -> DataLoader:\n",
    "    \n",
    "    dirf.process_path(root, dir_ok=True, \n",
    "                      file_ok=False, \n",
    "                      condition=dirf.image_dataset_directory, \n",
    "                      error_message=dirf.image_dataset_directory_error(root))\n",
    "    \n",
    "    # initialize the dataloader\n",
    "    ds = ImageFolder(root, transform=image_transform)\n",
    "    return initialize_train_dataloader(ds, \n",
    "                                       seed=seed, \n",
    "                                       batch_size=batch_size,\n",
    "                                       num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "                model: TransferAlexNet,\n",
    "                source_train_dir: DataLoader[Tuple[torch.Tensor, torch.Tensor]], \n",
    "                target_dir: DataLoader[torch.Tensor], \n",
    "                image_transform: tr,\n",
    "                optimizer: torch.optim.Optimizer, \n",
    "                lr_scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "                loss_coefficient: float,\n",
    "                device: str, \n",
    "                seed: int):\n",
    "\n",
    "    dl_source_train = get_dataloader(root=source_train_dir, \n",
    "                                     image_transform=image_transform,\n",
    "                                     batch_size=256, \n",
    "                                     seed=seed)\n",
    "\n",
    "    dl_target = get_dataloader(root=target_dir, \n",
    "                                image_transform=image_transform,\n",
    "                                batch_size=256, \n",
    "                                seed=seed)\n",
    "\n",
    "    source_batch = next(dl_source_train, None)\n",
    "    target_batch = next(dl_target, None)\n",
    "    source_over, target_over = source_batch is None , target_batch is None\n",
    "\n",
    "    while not source_over:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xs, ys = source_batch\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        # forward pass: source\n",
    "        model_output_source = model.forward(xs)\n",
    "        source_features, logits = model_output_source[:-1], model_output_source[-1]\n",
    "\n",
    "        # forward pass: target\n",
    "        xt, _ = target_batch\n",
    "        model_output_target = model.forward(xt)\n",
    "        target_features, _ = model_output_target[:-1], model_output_target[-1]\n",
    "\n",
    "        # the loss consists of\n",
    "        final_loss, cls_loss, feature_losses = calculate_loss(source_logits=logits,\n",
    "                                                              source_labels=ys, \n",
    "                                                              source_features=source_features,\n",
    "                                                              target_features=target_features,\n",
    "                                                              loss_coefficient=loss_coefficient, \n",
    "                                                              )\n",
    "        \n",
    "        # backpropagation\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # make sure to check the dataloaders\n",
    "        source_batch = next(dl_source_train, None)\n",
    "        target_batch = next(dl_target, None)\n",
    "        source_over, target_over = source_batch is None, target_batch is None\n",
    "\n",
    "        # if the target domain is already exhausted, then re-initialize it\n",
    "        if target_over: \n",
    "            dl_target = get_dataloader(root=target_dir, \n",
    "                                       image_transform=image_transform, \n",
    "                                       batch_size=256, \n",
    "                                       seed=seed+1)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
